---
title: "Regularized Model"
author: "Christian Pascual"
date: "3/18/2019"
output: html_document
---

```{r cleaning, message = FALSE }
library(tidyverse)
admit.data = read.csv(file = "./admission_predict.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    gre.std = (gre_score - mean(gre_score)) / sd(gre_score),
    toefl.std = (toefl_score - mean(toefl_score)) / sd(toefl_score),
    cgpa.std = (cgpa - mean(cgpa)) / sd(cgpa),
    uni.rating = factor(university_rating),
    sop.strength = factor(sop),
    lor.strength = factor(lor)
  ) %>% 
  select(serial_no, gre.std:lor.strength, research, chance_of_admit)
```

# Creating the regularized model

## What predictor variables did you include?

We are going to use all of the available predictors in the dataset. 

## What technique did you use, and why did you choose it? What assumptions, if any, are being made by using this technique?

With 3 categorical variables, the full model explodes to a model with 25 predictors. In order to create a more parsimonious model, we're going to use the LASSO to perform variable selection. We suspect that only some of the categories have an appreciable impact on the chance of admisison, so we'd like to confirm this with LASSO. LASSO has problems when there are more covariates than observations, but we do not run into this problem with this particular dataset.

## If there were tuning parameters, how did you pick their values?

5-fold cross-validation using glmnet

## How did you make your predictions?

10 fold cross validation. 

## Discuss the training/test performance if you have a test data set.

Same as above

## Which variables play important roles in predicting the response?


## What are the limitations of the models you used (if there are any)? Are the models flexible enough to capture the underlying truth?



Since we are performing a LASSO regression, we need to standardize the GRE, TOEFL, and CGPA scores.

```{r log-lasso, message = FALSE }
library(glmnet)

# Set up the cross-validation for cv.glmnet
# data contains categorical variables, need model.matrix
X = admit.data %>% select(gre.std:research)
fmt.X = model.matrix(~ gre.std + toefl.std + cgpa.std + uni.rating + 
                   sop.strength + lor.strength + research, X)
y = admit.data$chance_of_admit

# Fit a model to see how coefficients change with lambda
lasso = glmnet(fmt.X[,-1], y, alpha = 1)

# Perform the cross-validation to find the optimal lambda
lasso.cv = cv.glmnet(fmt.X[,-1], y, alpha = 1, type.measure = "mse")
cv.min.lambda = lasso.cv$lambda.min
lasso.fit = glmnet(fmt.X[,-1], y, alpha = 1, lambda = cv.min.lambda)

coef(lasso.fit)

```

```{r validation-plot }
plot(lasso, xvar = "lambda")
```






